# LLM-Powered Grading Assistant

## Overview

The LLM-Powered Grading Assistant is an advanced autograding application that transforms traditional educational assessment. By leveraging Retrieval-Augmented Generation (RAG) and Large Language Models (LLMs) such as LLaMA 2, the system offers a scalable, consistent, and intelligent grading solution tailored for modern educators.

Positioned in a rapidly growing EdTech market (~$250B), our system addresses core inefficiencies in grading — including excessive time consumption, subjectivity, and manual workload. On average, grading consumes over 66 hours in a 640-hour semester. Our AI-based assistant drastically cuts this burden, enabling faster grading, reduced human error, and personalized student feedback — all while boosting educator productivity.

## Key Features

- Automated Grading: Grades free-text answers, code, or assignments using advanced LLMs.
- Retrieval-Augmented Generation (RAG): Dynamically retrieves context from custom datasets for informed grading.
- LLM Integration: Uses LLaMA 2 and Transformers for answer evaluation and natural language feedback generation.
- Vector Database (VectorDB): Provides fast and relevant context retrieval through vectorized document storage.
- Instant Feedback: Students receive immediate, constructive feedback to accelerate learning.

## Tech Stack

- Language Models: Meta LLaMA 2
- Frameworks: PyTorch, Hugging Face Transformers
- Vector Store: FAISS / Pinecone (configurable)
- RAG: Custom pipeline integrating prompts with document retrieval
- Deployment: Streamlit / FastAPI (optional for demo)

## Demo

Watch the demo: https://lablab.ai/event/cohere-coral-hackathon/schrodingercats/quickscore-an-ai-grader

## Project Highlights

LLM-Powered Grading Assistant | PyTorch, RAG, Transformers, Prompt Engineering (60 hours)
- Developed an end-to-end grading pipeline using LLMs and RAG to evaluate subjective responses.
- Integrated a Vector Database to retrieve dynamic academic context for more accurate grading.
- Used LLaMA 2 to generate natural language feedback and scores, enhancing both learning outcomes and grading consistency.

## Impact and Vision

Our solution is set to make a strong mark in the EdTech sector, with a projected value of 1.5–3 billion dollars in automation-based academic solutions. By optimizing grading, this tool:
- Boosts educator productivity
- Enhances student engagement through rapid feedback
- Enables scalable, fair, and personalized academic evaluation

## Future Work

- LMS (Learning Management System) integration (e.g., Canvas, Moodle)
- Multilingual support
- Rubric-based grading fine-tuned for specific subjects
- Voice input for oral exams or viva assessments

## Contributing

Interested in improving or extending this project? Pull requests and suggestions are welcome.
